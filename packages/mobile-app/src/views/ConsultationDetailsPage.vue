<template>
  <ion-page>
    <ion-header :translucent="true">
      <ion-toolbar>
        <!-- Logo and Progress -->
        <div class="header-content">
          <div class="logo-header">
            <img src="/logo-simple.svg" alt="ÙŠÙƒØªØ§ÛŒØ§Ø±" class="header-logo" />
            <span class="header-title">ÙŠÙƒØªØ§ÛŒØ§Ø±</span>
          </div>
          <div class="progress-container">
            <div class="progress-bar">
              <div class="progress-fill" :style="{ width: progressPercent + '%' }"></div>
            </div>
            <span class="progress-text">{{ progressPercent }}Ùª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡</span>
          </div>
        </div>
      </ion-toolbar>
    </ion-header>
    
    <ion-content :fullscreen="true">
      <div class="content-wrapper">
        <!-- Main Question -->
        <div class="question-section">
          <h1 class="question-text">
            Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø³Ù… Ø¨Ù†ÙˆÛŒØ³ Ú†Ø§Ù„Ø´ ÛŒØ§ Ù…Ø´Ú©Ù„ÛŒ Ú©Ù‡ Ø§Ù„Ø§Ù† Ø¨Ø§Ù‡Ø§Ø´ Ø¯Ø±Ú¯ÛŒØ±ÛŒ Ùˆ Ø¨Ù‡ Ø®Ø§Ø·Ø±Ø´ Ù…ÛŒØ®ÙˆØ§ÛŒ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¨Ú¯ÛŒØ±ÛŒ Ú†ÛŒÙ‡
          </h1>
        </div>

        <!-- Voice Recording Button -->
        <div v-if="speechRecognitionSupported" class="recording-section">
          <button 
            class="mic-button" 
            :class="{ 
              'recording': isRecording, 
              'has-transcript': transcriptText.length > 0,
              'processing': isProcessing 
            }"
            @click="toggleRecording"
            :disabled="isProcessing"
          >
            <div class="mic-icon-wrapper">
              <ion-icon 
                :icon="isRecording ? stop : mic" 
                class="mic-icon"
              ></ion-icon>
              <div v-if="isRecording" class="pulse-ring"></div>
              <div v-if="isRecording" class="pulse-ring delayed"></div>
            </div>
          </button>
          
          <p class="recording-hint">
            <template v-if="!isRecording && !transcriptText">
              ØµØ­Ø¨Øª Ú©Ù†ØŒ Ù…Ø§ ØªØ¨Ø¯ÛŒÙ„Ø´ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ù‡ Ù…ØªÙ† ğŸ‘‡
            </template>
            <template v-else-if="isRecording">
              Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø·... Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚Ù Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯
            </template>
            <template v-else-if="transcriptText">
              Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¶Ø¨Ø· Ù†Ù…Ø§ÛŒÛŒØ¯
            </template>
          </p>

          <!-- Error Message with Type Instead option -->
          <div v-if="errorMessage" class="error-message">
            <div class="error-content">
              <ion-icon :icon="alertCircle"></ion-icon>
              <span>{{ errorMessage }}</span>
            </div>
            <a class="type-instead-link" @click="typeInstead">
              <ion-icon :icon="create"></ion-icon>
              Ø¨Ø¬Ø§ÛŒ Ø¢Ù† ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯
            </a>
          </div>
        </div>

        <!-- Transcribed Text Display/Edit -->
        <div v-if="shouldShowTextarea" class="transcript-section">
          <div class="transcript-card">
            <ion-textarea
              v-model="transcriptText"
              :placeholder="isRecording ? 'Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª...' : 'Ù…ØªÙ† Ø´Ù…Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯'"
              :auto-grow="true"
              :rows="6"
              class="transcript-textarea"
            ></ion-textarea>
            <div class="transcript-actions">
              <button 
                class="action-button secondary" 
                @click="clearTranscript"
                :disabled="isProcessing"
              >
                <ion-icon :icon="trash"></ion-icon>
                Ù¾Ø§Ú© Ú©Ø±Ø¯Ù†
              </button>
              <button 
                v-if="speechRecognitionSupported"
                class="action-button primary" 
                @click="toggleRecording"
                :disabled="isProcessing"
              >
                <ion-icon :icon="mic"></ion-icon>
                Ø¶Ø¨Ø· Ù…Ø¬Ø¯Ø¯
              </button>
            </div>
          </div>
        </div>

        <!-- Continue Button -->
        <div class="action-section">
          <ion-button 
            expand="block" 
            @click="handleContinue"
            :disabled="!canContinue || isSaving"
            class="continue-button"
          >
            <ion-icon v-if="!isSaving" :slot="iconSlot" :icon="continueArrowIcon"></ion-icon>
            <ion-spinner v-if="isSaving" :slot="iconSlot" name="crescent"></ion-spinner>
            {{ isSaving ? 'Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„...' : 'Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡' }}
          </ion-button>
        </div>

        <!-- Privacy Notice -->
        <div class="privacy-notice">
          <ion-icon :icon="lockClosed"></ion-icon>
          <p>Ø§Ø·Ù„Ø§Ø¹Ø§ØªØª Ù…Ø­Ø±Ù…Ø§Ù†Ù‡ Ù…ÛŒâ€ŒÙ…ÙˆÙ†Ù‡ Ùˆ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´Ù‡.</p>
        </div>
      </div>
    </ion-content>
  </ion-page>
</template>

<script setup lang="ts">
import {
  IonContent,
  IonHeader,
  IonPage,
  IonToolbar,
  IonButton,
  IonIcon,
  IonSpinner,
  IonTextarea,
  toastController,
  alertController,
} from '@ionic/vue'
import {
  mic,
  stop,
  arrowForward,
  arrowBack,
  lockClosed,
  trash,
  alertCircle,
  create,
} from 'ionicons/icons'
import { ref, computed, onMounted, onBeforeUnmount } from 'vue'
import { useRouter, useRoute } from 'vue-router'
import { useI18n } from 'vue-i18n'

const router = useRouter()
const route = useRoute()
const { locale } = useI18n()

// Consultation flow configuration
const TOTAL_STEPS = 10 // Total steps in consultation flow
const DEFAULT_STEP = 4 // Default to step 4 if not specified

// Get current step from route query param or use default
const currentStep = computed(() => {
  const stepParam = route.query.step
  if (stepParam) {
    const step = parseInt(stepParam as string, 10)
    return !isNaN(step) && step > 0 && step <= TOTAL_STEPS ? step : DEFAULT_STEP
  }
  return DEFAULT_STEP
})

// State
const isRecording = ref(false)
const isProcessing = ref(false)
const isSaving = ref(false)
const transcriptText = ref('')
const errorMessage = ref('')
const speechRecognitionSupported = ref(true)
const showTextarea = ref(false)

// Computed progress based on current step
const progressPercent = computed(() => {
  return Math.round((currentStep.value / TOTAL_STEPS) * 100)
})

// Watch for changes that should show the textarea
const shouldShowTextarea = computed(() => {
  return transcriptText.value || isRecording.value || !speechRecognitionSupported.value || showTextarea.value
})

// Web Speech API
let recognition: any = null
// Store finalized transcript separately - this is the committed text
let finalizedTranscript = ''
// Track if we're on mobile for special handling
const isMobileOrTablet = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ||
  (navigator.maxTouchPoints && navigator.maxTouchPoints > 2)

// Computed property for arrow icon based on locale
const continueArrowIcon = computed(() => {
  return locale.value === 'fa' ? arrowBack : arrowForward
})

// Computed property for icon slot position based on locale
const iconSlot = computed(() => {
  return locale.value === 'fa' ? 'end' : 'start'
})

// Initialize Speech Recognition
onMounted(() => {
  initializeSpeechRecognition()
})

onBeforeUnmount(() => {
  if (recognition) {
    recognition.stop()
  }
})

function initializeSpeechRecognition() {
  // Check for Web Speech API support
  const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
  
  if (!SpeechRecognition) {
    speechRecognitionSupported.value = false
    errorMessage.value = 'Ù…Ø±ÙˆØ±Ú¯Ø± Ø´Ù…Ø§ Ø§Ø² Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯'
    return
  }

  speechRecognitionSupported.value = true
  recognition = new SpeechRecognition()
  recognition.continuous = true
  recognition.interimResults = true
  
  // Set language based on current locale
  const langCode = locale.value === 'fa' ? 'fa-IR' : 'en-US'
  recognition.lang = langCode

  recognition.onstart = () => {
    isRecording.value = true
    isProcessing.value = false
    errorMessage.value = ''
    // Store the current text as the starting point for this recording session
    finalizedTranscript = transcriptText.value
  }

  recognition.onresult = (event: any) => {
    let interimTranscript = ''

    // Mobile-optimized result handling (inspired by debugger)
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i]
      const transcript = result[0].transcript
      const confidence = result[0].confidence
      
      // Mobile fix: treat confidence=0 as interim (not truly final)
      // On mobile, results can have isFinal=true but confidence=0, which means they're still uncertain
      const isTrulyFinal = result.isFinal && confidence !== 0
      
      if (isTrulyFinal) {
        // For final results: ALWAYS append (don't replace)
        // This ensures we accumulate all spoken words
        finalizedTranscript += (finalizedTranscript ? ' ' : '') + transcript
      } else {
        // Interim results: Show the current word being spoken
        // On mobile, we only keep the latest interim (no accumulation)
        if (isMobileOrTablet) {
          interimTranscript = transcript
        } else {
          interimTranscript += transcript
        }
      }
    }

    // Always SET the display value (never append to transcriptText directly!)
    // This shows: all finalized text + current interim word for live feedback
    if (interimTranscript) {
      // Show interim text with a space separator (the word being spoken right now)
      transcriptText.value = finalizedTranscript + (finalizedTranscript ? ' ' : '') + interimTranscript
    } else {
      // No interim, just show all finalized text
      transcriptText.value = finalizedTranscript
    }
  }

  recognition.onerror = (event: any) => {
    isRecording.value = false
    isProcessing.value = false
    
    switch (event.error) {
      case 'no-speech':
        errorMessage.value = 'ØµØ¯Ø§ÛŒÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯'
        break
      case 'audio-capture':
        errorMessage.value = 'Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª'
        break
      case 'not-allowed':
        errorMessage.value = 'Ù„Ø·ÙØ§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø±Ø§ Ù…Ø¬Ø§Ø² Ú©Ù†ÛŒØ¯'
        break
      default:
        errorMessage.value = 'Ø®Ø·Ø§ Ø¯Ø± Ø¶Ø¨Ø· ØµØ¯Ø§. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯'
    }
  }

  recognition.onend = () => {
    // When recording ends, ensure we only keep finalized text
    transcriptText.value = finalizedTranscript
    
    if (isRecording.value) {
      // Restart if still recording (for continuous recording)
      try {
        recognition.start()
      } catch (e) {
        isRecording.value = false
      }
    }
  }
}

async function toggleRecording() {
  if (!recognition) {
    await showAlert(
      'Ø®Ø·Ø§',
      'Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§ Ø§Ø² Ù…Ø±ÙˆØ±Ú¯Ø± Chrome Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.'
    )
    return
  }

  if (isRecording.value) {
    stopRecording()
  } else {
    startRecording()
  }
}

function startRecording() {
  try {
    errorMessage.value = ''
    recognition.start()
  } catch (error) {
    errorMessage.value = 'Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯'
  }
}

function stopRecording() {
  if (recognition) {
    isRecording.value = false
    recognition.stop()
    // Ensure we only show finalized text when stopped
    transcriptText.value = finalizedTranscript
  }
}

function clearTranscript() {
  transcriptText.value = ''
  finalizedTranscript = ''
  errorMessage.value = ''
}

function typeInstead() {
  errorMessage.value = ''
  showTextarea.value = true
  // Focus on the textarea after a short delay to ensure it's rendered
  setTimeout(() => {
    const textarea = document.querySelector('.transcript-textarea')
    if (textarea) {
      (textarea as HTMLElement).focus()
    }
  }, 100)
}

const canContinue = computed(() => {
  return transcriptText.value.trim().length > 10
})

async function handleContinue() {
  if (!canContinue.value) {
    await showToast('Ù„Ø·ÙØ§ Ø§Ø¨ØªØ¯Ø§ Ù…Ø´Ú©Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø´Ø±Ø­ Ø¯Ù‡ÛŒØ¯', 'warning')
    return
  }

  isSaving.value = true

  try {
    // TODO: Send to backend API
    // await apiClient.post('/api/consultations', {
    //   description: transcriptText.value.trim(),
    //   step: currentStep.value
    // })

    // Simulate API call
    await new Promise(resolve => setTimeout(resolve, 1500))

    await showToast('Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯', 'success')
    
    // Navigate to next step (e.g., AI chatbot)
    // TODO: Navigate to the next step in the consultation flow
    router.push('/tabs/chat')
    
  } catch (error) {
    await showToast('Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯', 'danger')
  } finally {
    isSaving.value = false
  }
}

async function showToast(message: string, color: 'success' | 'warning' | 'danger' = 'success') {
  const toast = await toastController.create({
    message,
    duration: 3000,
    position: 'bottom',
    color,
  })
  await toast.present()
}

async function showAlert(header: string, message: string) {
  const alert = await alertController.create({
    header,
    message,
    buttons: ['Ø¨Ø§Ø´Ù‡'],
  })
  await alert.present()
}
</script>

<style scoped>
/* Header Styling */
.header-content {
  display: flex;
  flex-direction: column;
  padding: 0.5rem 1rem;
  gap: 0.75rem;
}

.logo-header {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  justify-content: center;
}

.header-logo {
  width: 32px;
  height: 32px;
  object-fit: contain;
}

.header-title {
  font-size: 1.25rem;
  font-weight: 700;
  color: var(--ion-color-primary);
  font-family: var(--ion-font-family);
}

.progress-container {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
  align-items: center;
}

.progress-bar {
  width: 100%;
  height: 8px;
  background: var(--surface-3);
  border-radius: 10px;
  overflow: hidden;
  position: relative;
}

.progress-fill {
  height: 100%;
  background: linear-gradient(90deg, var(--ion-color-primary) 0%, var(--ion-color-primary-tint) 100%);
  border-radius: 10px;
  transition: width 0.5s ease;
  position: relative;
  overflow: hidden;
}

.progress-fill::after {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: linear-gradient(90deg, transparent 0%, rgba(255, 255, 255, 0.3) 50%, transparent 100%);
  animation: shimmer 2s infinite;
}

@keyframes shimmer {
  0% { transform: translateX(-100%); }
  100% { transform: translateX(100%); }
}

.progress-text {
  font-size: 0.85rem;
  color: var(--text-secondary);
  font-weight: 600;
  direction: rtl;
}

/* Content Wrapper */
.content-wrapper {
  padding: 2rem 1.5rem;
  max-width: 600px;
  margin: 0 auto;
  display: flex;
  flex-direction: column;
  gap: 2rem;
  min-height: 100%;
}

/* Question Section */
.question-section {
  text-align: center;
  animation: fadeIn 0.6s ease-out;
  padding: 1rem 0;
}

.question-text {
  font-size: 1.5rem;
  font-weight: 700;
  color: var(--text-primary);
  line-height: 1.6;
  margin: 0;
  direction: rtl;
  font-family: var(--ion-font-family);
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
}

/* Recording Section */
.recording-section {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 1.25rem;
  animation: fadeIn 0.8s ease-out 0.2s both;
}

.mic-button {
  width: 140px;
  height: 140px;
  border-radius: 50%;
  border: none;
  background: linear-gradient(135deg, var(--ion-color-primary) 0%, var(--ion-color-primary-tint) 100%);
  color: white;
  cursor: pointer;
  position: relative;
  transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
  box-shadow: 
    0 8px 24px rgba(212, 164, 62, 0.4),
    0 4px 12px rgba(0, 0, 0, 0.1);
  display: flex;
  align-items: center;
  justify-content: center;
  transform: scale(1);
}

.mic-button:hover:not(:disabled) {
  transform: scale(1.05);
  box-shadow: 
    0 12px 32px rgba(212, 164, 62, 0.5),
    0 6px 16px rgba(0, 0, 0, 0.15);
}

.mic-button:active:not(:disabled) {
  transform: scale(0.95);
  box-shadow: 
    0 4px 16px rgba(212, 164, 62, 0.4),
    0 2px 8px rgba(0, 0, 0, 0.1);
}

.mic-button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

.mic-button.recording {
  background: linear-gradient(135deg, var(--ion-color-danger) 0%, #ff6b6b 100%);
  animation: pulse 2s ease-in-out infinite;
}

.mic-button.processing {
  background: linear-gradient(135deg, var(--ion-color-medium) 0%, #b0b0b0 100%);
}

@keyframes pulse {
  0%, 100% {
    box-shadow: 
      0 8px 24px rgba(235, 68, 90, 0.5),
      0 4px 12px rgba(0, 0, 0, 0.1);
  }
  50% {
    box-shadow: 
      0 12px 32px rgba(235, 68, 90, 0.6),
      0 6px 16px rgba(0, 0, 0, 0.15);
  }
}

.mic-icon-wrapper {
  position: relative;
  display: flex;
  align-items: center;
  justify-content: center;
}

.mic-icon {
  font-size: 64px;
  color: white;
  filter: drop-shadow(0 2px 8px rgba(0, 0, 0, 0.2));
  position: relative;
  z-index: 1;
}

.pulse-ring {
  position: absolute;
  width: 140px;
  height: 140px;
  border: 3px solid rgba(255, 255, 255, 0.6);
  border-radius: 50%;
  animation: pulse-ring 2s ease-out infinite;
}

.pulse-ring.delayed {
  animation-delay: 1s;
}

@keyframes pulse-ring {
  0% {
    transform: scale(0.8);
    opacity: 1;
  }
  100% {
    transform: scale(1.4);
    opacity: 0;
  }
}

.recording-hint {
  font-size: 1rem;
  color: var(--text-secondary);
  text-align: center;
  margin: 0;
  direction: rtl;
  max-width: 350px;
  line-height: 1.5;
  font-weight: 500;
  transition: all 0.3s ease;
}

.error-message {
  display: flex;
  flex-direction: column;
  gap: 0.75rem;
  padding: 0.75rem 1rem;
  background: rgba(235, 68, 90, 0.1);
  border: 1px solid var(--ion-color-danger);
  border-radius: 12px;
  color: var(--ion-color-danger);
  font-size: 0.9rem;
  direction: rtl;
}

.error-content {
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.error-message ion-icon {
  font-size: 20px;
  flex-shrink: 0;
}

.type-instead-link {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  gap: 0.4rem;
  padding: 0.5rem 0;
  background: transparent;
  border: none;
  color: var(--ion-color-primary);
  font-size: 0.9rem;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s ease;
  font-family: var(--ion-font-family);
  text-decoration: underline;
  text-underline-offset: 3px;
}

.type-instead-link:hover {
  color: var(--ion-color-primary-shade);
  text-decoration-thickness: 2px;
}

.type-instead-link:active {
  transform: scale(0.98);
  color: var(--ion-color-primary-tint);
}

.type-instead-link ion-icon {
  font-size: 18px;
}

/* Transcript Section */
.transcript-section {
  animation: slideInUp 0.6s ease-out;
}

.transcript-card {
  background: var(--surface-1);
  border-radius: 16px;
  padding: 1.5rem;
  box-shadow: var(--card-shadow);
  border: 2px solid var(--glass-border);
  transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
  backdrop-filter: blur(10px);
}

.transcript-card:focus-within {
  border-color: var(--ion-color-primary);
  box-shadow: 
    var(--card-shadow-hover),
    0 0 0 4px rgba(212, 164, 62, 0.1);
  transform: translateY(-2px);
}

.transcript-textarea {
  --background: transparent;
  --color: var(--text-primary);
  --padding-start: 0;
  --padding-end: 0;
  --padding-top: 0;
  --padding-bottom: 0;
  font-size: 1rem;
  line-height: 1.6;
  direction: rtl;
  font-family: var(--ion-font-family);
  min-height: 150px;
}

.transcript-actions {
  display: flex;
  gap: 0.75rem;
  margin-top: 1rem;
  padding-top: 1rem;
  border-top: 1px solid var(--glass-border);
  direction: rtl;
}

.action-button {
  flex: 1;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 0.5rem;
  padding: 0.75rem 1rem;
  border-radius: 12px;
  border: none;
  font-size: 0.95rem;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
  font-family: var(--ion-font-family);
  transform: scale(1);
}

.action-button:hover:not(:disabled) {
  transform: scale(1.02);
}

.action-button:active:not(:disabled) {
  transform: scale(0.98);
}

.action-button:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.action-button.primary {
  background: linear-gradient(135deg, var(--ion-color-primary) 0%, var(--ion-color-primary-tint) 100%);
  color: white;
  box-shadow: 0 4px 12px rgba(212, 164, 62, 0.3);
}

.action-button.secondary {
  background: var(--surface-2);
  color: var(--text-secondary);
  border: 2px solid var(--glass-border);
}

.action-button ion-icon {
  font-size: 20px;
}

/* Action Section */
.action-section {
  margin-top: auto;
  padding-top: 1rem;
  animation: fadeIn 1s ease-out 0.4s both;
}

.continue-button {
  --background: linear-gradient(135deg, var(--ion-color-success) 0%, #42d77d 100%);
  --background-activated: var(--ion-color-success-shade);
  --box-shadow: 0 6px 20px rgba(45, 211, 111, 0.4);
  font-weight: 700;
  height: 58px;
  border-radius: 16px;
  text-transform: none;
  letter-spacing: 0.3px;
  font-size: 1.1rem;
  direction: rtl;
  font-family: var(--ion-font-family);
  transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
}

.continue-button:hover:not([disabled]) {
  --box-shadow: 0 8px 24px rgba(45, 211, 111, 0.5);
  transform: translateY(-2px);
}

.continue-button:not([disabled]):active {
  transform: translateY(0);
  --box-shadow: 0 4px 16px rgba(45, 211, 111, 0.3);
}

.continue-button ion-icon,
.continue-button ion-spinner {
  font-size: 24px;
}

/* Privacy Notice */
.privacy-notice {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  justify-content: center;
  padding: 1rem;
  background: rgba(212, 164, 62, 0.08);
  border-radius: 12px;
  direction: rtl;
  animation: fadeIn 1.2s ease-out 0.6s both;
}

.privacy-notice ion-icon {
  font-size: 20px;
  color: var(--ion-color-primary);
  flex-shrink: 0;
}

.privacy-notice p {
  margin: 0;
  font-size: 0.85rem;
  color: var(--text-secondary);
  line-height: 1.5;
}

/* Animations */
@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(20px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

@keyframes slideInUp {
  from {
    opacity: 0;
    transform: translateY(30px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

/* Responsive Design */
@media (max-width: 768px) {
  .question-text {
    font-size: 1.25rem;
  }
  
  .mic-button {
    width: 120px;
    height: 120px;
  }
  
  .mic-icon {
    font-size: 56px;
  }
  
  .pulse-ring {
    width: 120px;
    height: 120px;
  }
}
</style>
